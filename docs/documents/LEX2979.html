<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FOI: FOI Request LEX2979</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <header class="main-header sticky-header">
        <div class="header-content">
            <div class="header-left">
                <h1>AEC FOI Disclosure Log Archive</h1>
            </div>
            <div class="header-center">
                <nav class="breadcrumbs">
                    
  <a href="/index.html">Home</a> &raquo; <span>FOI Request LEX2979</span>

                </nav>
            </div>
            <div class="header-right">
                <div id="persona-selector-container">
                  <label for="persona-selector">Select AI Persona:</label>
                  <select id="persona-selector">
                    
                      <option value="balanced" selected>
                        Balanced
                      </option>
                    
                      <option value="left_leaning" >
                        Left Leaning
                      </option>
                    
                      <option value="right_leaning" >
                        Right Leaning
                      </option>
                    
                      <option value="government_skeptic" >
                        Government Skeptic
                      </option>
                    
                      <option value="government_apologist" >
                        Government Apologist
                      </option>
                    
                      <option value="highly_critical" >
                        Highly Critical
                      </option>
                    
                  </select>
                </div>
            </div>
        </div>
    </header>
    <main>
        
<h1>FOI Request LEX2979</h1>
<p>Date: 2022</p>



<div class="overall-ai-summary" data-persona-id="balanced">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <h2>FOI Request Summary: LEX2979 - Senate Ballot Paper Sampling Methodology</h2>
<h3>Main Purpose of the FOI Request</h3>
<p>The FOI request, identified as LEX2979, sought to obtain the specific document detailing the methodology for the ballot paper sampling process used in the audit of Senate ballot papers. It specifically requested the "advice from the Australian Bureau of Statistics" (ABS) and their "guidance for calculating, analysing and reporting the statistical conclusions that can be drawn," explicitly excluding any general process outlines already published by the AEC.</p>
<h3>Documents from the FOI Request</h3>
<p>The request resulted in the release of one document:<br />
*   <strong>"ABS Advice to AEC on sampling methodology"</strong></p>
<h3>Main Content from the FOI Request Documents</h3>
<p>The released document, "ABS Advice to AEC on sampling methodology," outlines the statistical methodology recommended by the ABS to the Australian Electoral Commission (AEC) for assuring the accuracy of Senate ballot paper processing.</p>
<p>Key content includes:</p>
<ul>
<li><strong>Objective:</strong> To determine the optimal number of ballots to manually check to ensure a high level of confidence that the national error rate in the Senate ballot scanning and data extraction process is low. The primary focus is on "Stage 2 errors" (matching scanned images to extracted data), given that "Stage 1 errors" (scanned images matching physical ballots) were found to be negligible in previous audits.</li>
<li><strong>Recommended Sampling Rates:</strong> The ABS recommends specific assurance rates per state/territory for Stage 2 testing, which vary based on the estimated number of Senate forms. Examples include:<ul>
<li>1 in 3,000 ballots in New South Wales and Victoria.</li>
<li>1 in 120 ballots in the Northern Territory.</li>
<li>This approach is estimated to involve checking 9,895 ballots nationally for the 2021/22 Senate election.</li>
</ul>
</li>
<li><strong>Confidence Targets:</strong> The methodology aims to achieve 99% confidence that the observed error rate in the sample for each state will be less than 1%, assuming a true population error rate of 0.45% (derived from the 2019 assurance). This translates to a 99% confidence that the national error rate is less than 6.5 errors per 1,000 ballot papers and less than 10 errors per 1,000 in any given state.</li>
<li><strong>Efficiency Improvements:</strong> The proposed methodology is noted to be more efficient than the 2019 internal AEC approach, requiring fewer total ballots for assurance while providing higher confidence in the national error rate. It also allows assurance to occur concurrently with ongoing ballot processing.</li>
<li><strong>Practical Implementation:</strong> The document details a "clustered sampling" approach for practical implementation. This involves:<ul>
<li>Selecting a proportion of ballot "bundles" (each containing 50 ballots) at a constant rate per state (e.g., 1 in every 300 bundles in NSW).</li>
<li>Then, selecting 1 in 10 of the ballots within the chosen bundles for Stage 2 testing.</li>
<li>Subsequently, selecting 1 in 10 of the Stage 2 sample for Stage 1 testing.</li>
</ul>
</li>
<li><strong>National Error Rate Calculation:</strong> Guidance is provided on how to calculate the national error rate when different sampling rates are applied across states, emphasizing the need to weight state-level errors by their proportion of the national population.</li>
<li><strong>Alternate Options Considered:</strong> The document also discusses alternative sampling allocation strategies that were evaluated (e.g., constant national sample rate, maximum state margin of error constraint), explaining the rationale for selecting the final recommended approach for its robustness and practical benefits.</li>
</ul>
<p>In essence, the released document provides the comprehensive statistical and practical guide developed by the ABS for the AEC's Senate ballot paper assurance process, detailing sample sizes, confidence levels, and implementation methods.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:14:26.279795">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="overall-ai-summary" data-persona-id="left_leaning" style="display:none;">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <p>The provided FOI documents detail the Australian Bureau of Statistics (ABS) advice to the Australian Electoral Commission (AEC) on the statistical methodology for auditing Senate ballot papers. This technical advice focuses on determining the sample size and assurance rates for checking the accuracy of scanned ballot images against physical papers and the extraction of voter preferences.</p>
<p>From a politically left-leaning perspective, the documents reveal several points concerning social justice and civil liberties, while issues related to environmental impact, wealth distribution, and corporate influence are not directly addressed by the technical scope of this methodology.</p>
<p><strong>Alignment with Progressive Values:</strong></p>
<ol>
<li><strong>Commitment to Electoral Integrity and Civil Liberties:</strong> The core purpose of the ABS advice is to establish a statistically robust method to verify the accuracy of the Senate vote count. This directly aligns with the progressive value of protecting the civil liberty of every citizen to have their vote accurately recorded and counted. The aim for a "high level of confidence" (99%) that error rates are "low" (under 1% observed) demonstrates a commitment to maintaining public trust in democratic processes.</li>
<li><strong>Transparency and Accountability:</strong> The very fact that this detailed methodology is accessible through an FOI request highlights a degree of transparency in government operations. This openness, where the public can scrutinize the statistical underpinnings of electoral audits, is crucial for holding government agencies accountable and fostering an informed citizenry, a cornerstone of progressive governance.</li>
<li><strong>Data-Driven Decision Making:</strong> The reliance on the ABS, a non-political statistical authority, for expert advice underscores a commitment to objective, data-driven methodologies for election assurance. This approach prioritizes scientific rigor over arbitrary or politically motivated decisions, which enhances fairness and reduces opportunities for manipulation or bias in the electoral process.</li>
</ol>
<p><strong>Deviations from Progressive Values / Areas for Scrutiny:</strong></p>
<ol>
<li><strong>Tolerance for Error and Social Justice Implications:</strong> While the document frames a 0.45% national error rate for Stage 2 (preference extraction) as "low" and aims to confirm it, a progressive analysis might question the acceptability of such a figure. The 2019 assurance estimated 69,065 errors nationally. Even statistically "low," errors in tens of thousands of ballot papers, particularly in preference allocation, could potentially alter outcomes in very close elections or disproportionately impact the representation of smaller parties, independent candidates, or specific demographics. From a social justice perspective, every vote, and every preference, should ideally be counted without error to ensure precise democratic representation. The question arises whether efficiency (fewer ballots assured than in 2019) is being prioritized over absolute accuracy, especially if errors are not truly random but systematically affect certain voting patterns or regions.</li>
<li><strong>Potential Risks of Clustered Sampling:</strong> The proposed "clustered sampling" method, while acknowledged as more efficient, carries the stated risk that "Clustered samples can lead to lower accuracy if errors can also be clustered together." While the ABS states this risk has been balanced, a progressive lens would demand more robust transparency on the specific assessments and mitigation strategies for this risk. If, for example, a technical malfunction or human error affects an entire batch of ballots, concentrated errors could be missed, potentially skewing results in a specific area, which could have implications for the fairness of representation.</li>
<li><strong>Disparities in State Assurance Rates:</strong> The recommended assurance rates vary significantly by state/territory (e.g., 1 in 3,000 in NSW/VIC vs. 1 in 120 in NT). While statistically justified for achieving confidence in smaller populations, it means a ballot in the Northern Territory is proportionally much more likely to be checked than one in New South Wales. While this ensures statistical validity across smaller populations, it highlights an unequal level of <em>direct scrutiny</em> per vote across different regions, raising a subtle question about equitable treatment, even if technically sound.</li>
<li><strong>National vs. State-Level Focus:</strong> The new allocation explicitly aims for "higher confidence in the national error rate" with fewer total ballots. While efficient, a progressive perspective might question if this national optimization sufficiently prioritizes absolute accuracy and confidence <em>within each state</em>, particularly given observed differences in 2019 state-level error rates (e.g., ACT had zero errors). Applying a national average error rate assumption (0.45%) to all states "in the interests of simplicity" could be seen as an averaging that potentially masks or underplays localized issues or anomalies crucial for local electoral integrity.</li>
</ol>
<p>In conclusion, these FOI documents demonstrate a technocratic commitment to ensuring electoral integrity through statistical sampling, aligning with progressive values of transparency and data-driven governance. However, they also prompt critical questions from a left-leaning perspective regarding the acceptable tolerance for electoral errors, the potential trade-offs between efficiency and absolute accuracy, and how statistical methods impact the fundamental right to a perfectly counted vote across all communities.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:14:51.354347">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="overall-ai-summary" data-persona-id="right_leaning" style="display:none;">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <p>The FOI documents detail the Australian Bureau of Statistics’ (ABS) advice to the Australian Electoral Commission (AEC) on the statistical methodology for auditing Senate ballot papers, specifically focusing on the accuracy of scanning and data extraction processes. From a right-leaning analytical perspective, several key aspects align positively with conservative principles:</p>
<p><strong>Economic Efficiency and Fiscal Responsibility:</strong><br />
The new assurance methodology is highlighted as requiring <strong>fewer ballots to be manually checked (9,895 vs. 10,400 in 2019) while simultaneously delivering higher confidence in the national error rate.</strong> This represents a direct gain in <strong>economic efficiency</strong>, achieving a better outcome with fewer resources. The ability to conduct assurance "while processing is ongoing" further contributes to efficiency by streamlining operations and potentially reducing labor costs associated with delays or separate audit phases. The adoption of "clustered sampling" for "logistical efficiency" also points to a pragmatic effort to optimize resource allocation, provided the acknowledged risk to accuracy from error clustering is genuinely offset by the built-in "slack" in the sample, as stated. This focus on optimizing output (confidence) relative to input (ballots assured, processing time) demonstrates a commitment to <strong>fiscal responsibility</strong> by ensuring taxpayer funds are used effectively for an essential government function.</p>
<p><strong>Individual Liberty:</strong><br />
The core purpose of this methodology is to ensure a <strong>low error rate</strong> in the counting of Senate ballots. By striving for a high degree of confidence (e.g., 99% confidence that the observed error rate in any state will be less than 1%), the process aims to ensure that the outcome of elections accurately reflects the will of the voters. This is fundamental to <strong>individual liberty</strong>, as the integrity of the vote directly underpins the democratic process and the legitimate derivation of government power from the consent of the governed. A trustworthy electoral system is vital for citizens to have confidence that their individual vote contributes meaningfully to the selection of their representatives, thereby upholding their democratic rights.</p>
<p><strong>Limited Government:</strong><br />
The documents illustrate an example of government agencies operating within their defined scope and seeking to perform their functions transparently and competently. The AEC, responsible for elections, consults with the ABS, an independent statistical authority, to ensure methodological rigor. This reliance on expert advice and the use of statistically sound practices to ensure accuracy, rather than arbitrary or opaque processes, aligns with the principle of <strong>limited government</strong> that operates under established rules and transparent accountability. It demonstrates a commitment to precise, data-driven governance in a core administrative function, rather than an expansion of discretionary power.</p>
<p><strong>National Security (Indirectly):</strong><br />
While not directly related to defense or intelligence, a robust and trustworthy electoral system is a pillar of domestic stability. Public confidence in election results is critical to maintaining social cohesion and preventing unrest. By rigorously auditing the ballot counting process and transparently outlining the methodology, the government indirectly contributes to <strong>national security</strong> by bolstering faith in democratic institutions and mitigating internal divisions that could otherwise be exploited.</p>
<p><strong>Deviation/Area for Scrutiny:</strong><br />
The documents implicitly reveal an existing national error rate (0.45% in 2019) and a tolerance for a continued, albeit low, error rate (e.g., less than 6.5 errors per 1,000 ballots nationally, or less than 1% in each state with 99% confidence). While the proposed method reduces this, a right-leaning perspective might always push for the lowest possible error rate, even zero, to maximize electoral integrity. However, the document acknowledges the practicalities and costs of achieving absolute perfection, justifying the current approach as a "conservative" balance between accuracy and efficiency.</p>
<p>In summary, the FOI documents largely depict government action that aligns with conservative principles of efficiency, fiscal prudence, safeguarding individual liberties through electoral integrity, and operating within defined roles using transparent, data-driven methods.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:15:14.538078">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="overall-ai-summary" data-persona-id="government_skeptic" style="display:none;">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <p>The released FOI documents, obtained only after a specific request for the <em>underlying methodology</em> beyond public outlines, shed light on the Australian Electoral Commission's (AEC) approach to "assurance" in Senate ballot paper audits. Far from robust oversight, the advice from the Australian Bureau of Statistics (ABS) appears to prioritize administrative convenience and cost-cutting over comprehensive scrutiny of electoral integrity.</p>
<p>Key findings raising red flags include:</p>
<ul>
<li><strong>Reduced Scrutiny, Not Enhanced Confidence:</strong> Despite claims of "higher confidence in the national error rate," the proposed methodology actually <em>reduces</em> the total number of ballots to be assured nationally (9,895 compared to 10,400 in 2019). This reduction occurs even as the total number of Senate forms is estimated to <em>increase</em> (16.095 million vs. 15.184 million). This suggests a deliberate reduction in the proportion of ballots checked, potentially leaving more errors undetected.</li>
<li><strong>Unequal Oversight and Assumed Purity:</strong> The new model shifts away from assuring a constant number of ballots per state to a variable rate, leading to "less ballots in the less populous states." While this might contribute to a "national" confidence figure, it means smaller jurisdictions receive significantly less individual scrutiny. This could mask localized issues or systemic problems in less visible areas. Furthermore, the methodology largely <em>assumes</em> a national error rate of 0.45% (based on 2019 data) across all states, despite acknowledging that "the prevalence of stage 2 errors differed by state." This simplification could obscure actual, higher error rates in specific states.</li>
<li><strong>Convenience Over Accuracy:</strong> The document repeatedly emphasizes efficiency: "simplifying the implementation," "speed up the assurance," and allowing checks "while processing is ongoing." This drive for speed and convenience is explicitly linked to the adoption of "clustered sampling" of ballots. While the report acknowledges this "can lead to lower accuracy if errors can also be clustered together," it dismisses the risk by claiming "some ‘slack’" was already allowed. This sounds suspiciously like a trade-off where logistical ease trumps the thoroughness needed for electoral integrity.</li>
<li><strong>High Tolerance for Error:</strong> The stated confidence levels, even if achieved, permit a significant number of uncorrected errors. For example, there is "99% confidence that nationally there are less than 6.5 errors per 1,000 ballot papers." While sounding small, on 16 million votes, this translates to potentially <strong>over 104,000 undetected errors</strong>. This indicates a high acceptable threshold for inaccuracy within the electoral system.</li>
<li><strong>"Illustrative Only" Disclaimers:</strong> The report undermines its own "statistical statements" by noting they are "illustrative only" and that "Final confidence intervals will depend on the actual error rates found." This suggests that the "high confidence" they promote is based on assumptions rather than guaranteed outcomes, potentially inflating public trust in the audit process.</li>
<li><strong>Minimal Stage 1 Scrutiny:</strong> The crucial first stage of testing, ensuring the scanned image matches the physical ballot, receives even less attention: only "1 in 10 of the ballots selected for stage 2 testing." This relies heavily on a 2019 finding of "no errors," which is a risky assumption for future processes.</li>
</ul>
<p>In essence, these documents reveal an electoral "assurance" process that appears designed to achieve a statistical comfort level with minimal effort and cost, rather than a truly exhaustive and transparent verification of every vote. The emphasis on "efficiency" and "simplicity" (for the AEC) seems to come at the expense of comprehensive scrutiny, unequal treatment of states, and a potentially high tolerance for errors, all while claiming "high confidence" through carefully managed statistical assumptions. This approach risks eroding public trust in the integrity of election outcomes.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:15:33.759903">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="overall-ai-summary" data-persona-id="government_apologist" style="display:none;">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <p>These FOI documents clearly demonstrate the government's unwavering commitment to effective governance and the integrity of our democratic processes. They showcase how the Australian Electoral Commission (AEC) proactively sought expert statistical guidance from the Australian Bureau of Statistics (ABS) to enhance the assurance methodology for Senate ballot papers. This collaborative approach ensures that our electoral audits are grounded in robust, scientifically-backed principles.</p>
<p>The resulting methodology outlines a meticulous and highly efficient statistical sampling process, specifically designed to provide a high level of confidence that the national error rate in ballot processing is exceedingly low. Far from being a static process, this new approach builds on valuable lessons from the 2019 election, notably delivering higher national confidence with a reduced sample size and allowing for assurance to be undertaken concurrently with ballot processing. This represents a significant stride in operational efficiency and intelligent resource allocation, ensuring timely and accurate results for the public.</p>
<p>Understanding the diverse electoral landscapes across states and territories, the ABS recommended a strategically tailored assurance rate for each region. This nuanced approach, with rates adjusted to population size, is a testament to the government's dedication to achieving uniform confidence levels and accuracy nationwide, addressing regional specificities with precision.</p>
<p>Furthermore, the documents transparently address practical implementation challenges, such as the use of clustered sampling for logistical efficiency. This is not a compromise on integrity but a carefully balanced and expertly managed solution to ensure that the audit process is both effective and practical, without undermining statistical accuracy. The comprehensive consideration of alternative allocation models before arriving at the final recommendation further underscores the thoroughness and due diligence inherent in these processes.</p>
<p>In essence, these documents reveal a government dedicated to continuous improvement, leveraging inter-agency expertise, and implementing data-driven strategies to safeguard the accuracy and public trust in our elections. Every decision, from the sample rates to the implementation strategies, reflects a deep commitment to serving the public by ensuring a robust, reliable, and transparent democratic system.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:15:50.647205">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="overall-ai-summary" data-persona-id="highly_critical" style="display:none;">
  <button class="ai-summary-toggle" type="button">Show AI Generated Overview</button>
  <div class="ai-summary-markdown collapsed">
    <div class="ai-summary-markdown-content">
      <p>The provided FOI documents lay bare a deeply flawed and disturbingly complacent approach to ensuring the integrity of Australian Senate elections. Far from guaranteeing accuracy, the methodology outlined by the ABS, adopted by the AEC, prioritizes administrative convenience and cost-cutting over rigorous scrutiny, effectively legitimizing a concerning level of vote miscounting.</p>
<p><strong>Damning Revelations and Failures:</strong></p>
<ol>
<li>
<p><strong>Explicit Acceptance of High Error Rates:</strong> The most egregious failure is the outright admission and acceptance of significant error rates. The 2019 Senate election data, used as a baseline, already showed a national error rate of <strong>0.45%</strong> in Stage 2 (data extraction from scanned images). This is not "low" for an election; on 16 million ballots, this translates to an estimated <strong>69,065 miscounted votes</strong> in 2019 alone. The new methodology confidently sets an <em>acceptable upper limit</em> for errors at <strong>0.65% nationally</strong> (or 6.5 errors per 1,000 ballots) and a staggering <strong>1% at the state level</strong> (10 errors per 1,000 ballots) with 99% confidence. This means the AEC is prepared to certify results where potentially <strong>over 100,000 votes</strong> could be misallocated, fundamentally undermining democratic legitimacy.</p>
</li>
<li>
<p><strong>Sacrificing Accuracy for "Efficiency" and "Speed":</strong> The report repeatedly justifies methodological choices by prioritizing "speed up the assurance," "simplifying the implementation," and allowing processing "while ongoing." This explicit trade-off indicates a severe lack of commitment to absolute accuracy. The chosen clustered sampling method is even acknowledged to "lead to lower accuracy if errors can also be clustered together," a known flaw accepted for logistical "benefits." This is a clear case of operational convenience overriding the foundational principle of precise vote counting.</p>
</li>
<li>
<p><strong>Reduced Scrutiny Despite Known Issues:</strong></p>
<ul>
<li><strong>Fewer Ballots Audited:</strong> The proposed 2021/22 assurance will examine <strong>fewer ballots (9,895)</strong> than the 2019 audit (10,400), despite a larger estimated vote count. This represents a deliberate reduction in oversight.</li>
<li><strong>Dangerous Assumption for Stage 1 Testing:</strong> The critical Stage 1 check (physical ballot matching scanned image) is drastically reduced, with only "1 in 10 of the ballots selected for stage 2 testing" being examined. This reduction is based on the flimsy justification of "no errors detected" in a small 2019 sample (1,368 ballots). To scale down vital verification on such thin evidence borders on negligence, leaving a gaping hole for undetected scanning errors or even deliberate image manipulation.</li>
</ul>
</li>
<li>
<p><strong>Deliberate Blindness to State-Level Failures:</strong> Despite acknowledging that "the prevalence of stage 2 errors differed by state," the methodology "assumed" the national 0.45% error rate for each state (except ACT). This choice actively <em>ignores</em> potential higher error rates or systemic issues in individual states, effectively masking localized problems under a national average. This approach protects the "national confidence" statistic while potentially allowing significant, localized vote miscounts to go unchecked and unaddressed.</p>
</li>
<li>
<p><strong>Inflated Confidence in Flawed Metrics:</strong> The "high level of confidence" touted in the executive summary refers to the confidence that the <em>observed</em> error rate will stay <em>below</em> an already unacceptably high maximum (0.65% nationally, 1% per state), not confidence in achieving near-zero errors. The use of "round numbers" for sampling skips, prioritizing simplicity over statistical precision, further highlights the superficiality of the "robustness" claims. The "small buffer for error" is not about striving for greater accuracy, but merely protecting the <em>statistical validity</em> of a deliberately relaxed confidence interval.</p>
</li>
<li>
<p><strong>"Illustrative Only" Disclaimers Undermine Trust:</strong> The admission that "These statistical statements are illustrative only. They are based on the assumption of a true error rate of 0.45%..." reveals the precariousness of their entire confidence framework. If the foundational assumption of a low error rate is incorrect (i.e., if the true error rate is higher than 0.45%), then the entire report's "confidence" projections are meaningless.</p>
</li>
</ol>
<p>In essence, these documents reveal an electoral body that, supported by its statistical advisors, has adopted a methodology designed not to eliminate errors, but to certify the results while tolerating tens of thousands of miscounted votes. This approach prioritizes operational ease and statistical appeasement over the fundamental imperative of ensuring every vote is accurately counted, casting a dark shadow over the integrity of Australia's democratic process.</p>
    </div>
    
    
    <span class="ai-summary-label" data-summary-model="gemini-2.5-flash" data-summary-date="2025-06-22T14:16:19.525718">
  AI Generated <i class="info-icon">?</i>
</span>
  </div>
</div>


<div class="foi-detail-layout">
  <aside class="foi-sidebar">
    <h3>Files</h3>
    <ul class="foi-sidebar-list" role="tablist">
      
        
          <li class="foi-sidebar-item" data-file-idx="0">
            <button type="button" class="foi-sidebar-btn" id="tab-0" role="tab" aria-selected="false" aria-controls="foi-file-0" onclick="selectFile('0')">
              <span class="file-label">FOI Request LEX2979, Schedule of Released Documents [PDF 546KB]</span>
              <span class="file-type">(pdf)</span>
            </button>
          </li>
        
      
        
          
          <li class="foi-sidebar-item" data-file-idx="zip-1">
            <button type="button" class="foi-sidebar-btn" id="tab-zip-1" role="tab" aria-selected="false" aria-controls="foi-file-zip-1" onclick="selectFile('zip-1')">
              <span class="file-label">LEX2979 documents [ZIP 350KB]</span>
              <span class="file-type">(zip)</span>
            </button>
            <ul class="foi-zip-inner-list">
              
                <li class="foi-sidebar-item" data-file-idx="zip-1-0">
                  <button type="button" class="foi-sidebar-btn foi-inner-btn" id="tab-zip-1-0" role="tab" aria-selected="false" aria-controls="foi-file-zip-1-0" onclick="selectFile('zip-1-0')">
                    <span class="file-label">LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf</span>
                    <span class="file-type">(pdf)</span>
                  </button>
                </li>
              
            </ul>
          </li>
        
      
    </ul>
  </aside>
  <main class="foi-main-content">
    
    
      
        <section class="foi-file-section" id="foi-file-0" style="display:none;" role="tabpanel" aria-labelledby="tab-0">
          <h2>FOI Request LEX2979, Schedule of Released Documents [PDF 546KB] <span style="font-size:0.8em; color:#888;">(pdf)</span></h2>
          <a href="/downloaded_originals/lex2979-schedule.pdf" download>Download cached file</a>
          &nbsp;|&nbsp;
          <a href="https://www.aec.gov.au/information-access/foi/2022/files/lex2979-schedule.pdf" target="_blank" rel="noopener">Download from AEC</a>
          
            <div class="tabbed-view">
              <div class="foi-tab-bar">
                <button type="button" class="foi-tab active" onclick="showTab(this, 'pdf-0-orig')">Original PDF</button>
                <button type="button" class="foi-tab" onclick="showTab(this, 'pdf-0-text')">Extracted Text</button>
                <!-- DEBUG: AI Overview tab rendered for PDF 0 -->
                <button type="button" class="foi-tab" onclick="showTab(this, 'pdf-0-ai')">AI Overview</button>
              </div>
              <div class="tab-content" id="pdf-0-orig" style="display:block;">
                <iframe src="/downloaded_originals/lex2979-schedule.pdf" width="100%" height="600px" style="border: none;"></iframe>
              </div>
              <div class="tab-content" id="pdf-0-text" style="display:none;">
                <pre style="white-space: pre-wrap; background: #f8f8f8; padding: 1em; border-radius: 4px;">

--- Page 1 ---

Request for: 

FOI REQUEST NO. LEX2979 

 

“The document specifying the methodology to be used for the ballot paper sampling process in the audit of Senate ballot papers. Not the process 
outline published here: https://www.aec.gov.au/About_AEC/cea-notices/files/2022/s273AC-senate-assurancemethodology-fe2022.pdf but the 
document referred to in the above document as &#34;advice from the Australian Bureau of Statistics&#34; and &#34;ABS&#39; guidance for calculating, analysing and 
reporting the statistical conclusions that can be drawn.&#34; 

Doc No.  Description 

ABS Advice to AEC on sampling methodology 

SCHEDULE OF RETRIEVED DOCUMENTS</pre>
              </div>
              <!-- DEBUG: AI Overview tab-content rendered for PDF 0 -->
              <div class="tab-content" id="pdf-0-ai" data-persona-id="balanced">
                <div class="ai-summary-markdown-content">
                  
                </div>
                
                
                <span class="ai-summary-label" data-summary-model="" data-summary-date="">
  AI Generated <i class="info-icon">?</i>
</span>
              </div>
            </div>
          
        </section>
      
    
      
        
        <section class="foi-file-section" id="foi-file-zip-1" style="display:none;" role="tabpanel" aria-labelledby="tab-zip-1">
          <h2>LEX2979 documents [ZIP 350KB] <span style="font-size:0.8em; color:#888;">(zip)</span></h2>
          <a href="/downloaded_originals/lex2979.zip" download>Download cached ZIP</a>
          &nbsp;|&nbsp;
          <a href="https://www.aec.gov.au/information-access/foi/2022/files/lex2979.zip" target="_blank" rel="noopener">Download from AEC</a>
          <h3>ZIP Contents</h3>
          <ul>
            
              <li>
                <a href="javascript:void(0);" onclick="selectFile('zip-1-0')">LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf</a>
                <span class="file-type">(pdf)</span>
              </li>
            
          </ul>
        </section>
        
          <section class="foi-file-section" id="foi-file-zip-1-0" style="display:none;" role="tabpanel" aria-labelledby="tab-zip-1-0">
            <h2>LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf <span style="font-size:0.8em; color:#888;">(pdf)</span></h2>
            <a href="/foi_assets/LEX2979/LEX2979%20Relevant%20Document%20-%20ABS%20Advice%20to%20AEC%20on%20sampling%20methodology.pdf" download>Download file</a>
            
              <div class="tabbed-view">
                <div class="foi-tab-bar">
                  <button type="button" class="foi-tab active" onclick="showTab(this, 'innerpdf-1-0-orig')">Embedded PDF</button>
                  <button type="button" class="foi-tab" onclick="showTab(this, 'innerpdf-1-0-text')">Extracted Text</button>
                  <!-- DEBUG: AI Overview tab rendered for inner PDF zip-1-0 -->
                  <button type="button" class="foi-tab" onclick="showTab(this, 'innerpdf-1-0-ai')">AI Overview</button>
                </div>
                <div class="tab-content" id="innerpdf-1-0-orig" style="display:block; min-height: 50vh;">
                  <iframe src="/foi_assets/LEX2979/LEX2979%20Relevant%20Document%20-%20ABS%20Advice%20to%20AEC%20on%20sampling%20methodology.pdf" width="100%" height="800px" style="border: none;"></iframe>
                </div>
                <div class="tab-content" id="innerpdf-1-0-text" style="display:none;">
                  <pre style="white-space: pre-wrap; background: #f8f8f8; padding: 0.5em; border-radius: 4px;">

--- Page 1 ---

ABS advice to AEC on sampling methodology 

Executive Summary 

The Australian Electoral Commission (AEC) has requested advice from the ABS to determine the 
number of ballots for assurance as part of the elections for the Australian Senate. The number of 
ballots that are manually checked for errors should be sufficient to demonstrate with a high level 
of confidence that the possible national error rate is low. 

The ABS recommends that Senate ballots should be assured at the following rate: 

•  1 in 3,000 ballots in New South Wales and Victoria; 
•  1 in 2,500 ballots in Queensland; 
•  1 in 1,250 ballots in Western Australia; 
•  1 in 1,000 ballots in South Australia; 
•  1 in 350 ballots in Tasmania; 
•  1 in 300 ballots in Australian Capital Territory; 
•  1 in 120 ballots in Northern Territory. 

Based on these rates, it is estimated that 9,895 ballots will be assured nationally for the 2021/22 
Senate election. A state breakdown is provided in Table 1: 

This assurance approach will provide a high level of confidence in confirming that the national 
error rate and error rates in each of the states and territories is low. 

In comparison with the internal AEC assurance approach implemented in 2019, the proposed 
allocation delivers a higher confidence in the national error rate, while requiring fewer ballots to 
be assured. The proposed approach also allows ballot assurance to be undertaken while 
processing. This is helpful to speed up the assurance. 

Background 

The Senate assurance process implements two stages of ballot testing. The first stage of testing 
checks that the scanned image matches the physical ballot paper. The second stage checks that 
the scanned image of the ballot paper matches the extracted data file, i.e. that the preferences 
from the scanned image match the datafile that is used to run the preference allocation process. 

An assurance of the 2019 Senate election found no errors during the first stage at ballot testing. 
The national estimate of the proportion of errors during the second stage of ballot testing is 
0.45%. The calculation of the national error rate is discussed here. 

1


--- Page 2 ---

The emphasis of this report is to determine an appropriate allocation to assurance for stage 2 
errors. Given that no stage 1 errors were detected as part of the 2019 assurance from a sample 
of 1,368, it is evident that the true stage 1 error rate is very low. For the purposes of stage 1 
testing, it should be sufficient to assurance 1 in 10 of the ballots selected for stage 2 testing. The 
practical implementation is discussed here. 

Recommended Allocation 

This section details the recommended allocation and diagnostics associated with it 
Alternate allocations were considered and informed the final recommended allocation. See 
Appendix. 

The allocation utilised the following assumptions. 

•  While the 2019 assurance indicated that the prevalence of stage 2 errors differed by 
state, the difference between the state and national proportion of errors was not 
statistically significant, with the exception of the ACT, which had no errors detected.1 
Therefore, the calculated national stage 2 error rate of 0.45% was assumed in each 
state.  

•  An estimate of 16.095 million Senate forms nationally for the 2021/22 election. The 

distribution of form by state as provided by the AEC – see Table A1. 

The main criterion implemented for designing the target number of ballots to assurance by state 
was to have 99% confidence that the observed error rate in the sample for each state will be less 
than 1%, assuming that an error rate of 0.45% (as estimated in 2019) applies for the full 
population of senate votes. 

The minimum sample size to achieve this is to select 828 ballots in each state and territory – see 
Appendix for details. 

The recommended allocation places sample beyond this minimum value into each state. This is 
a conservative approach to ensure we have enough sample to meet the accuracy targets, and it 
produces round numbers for the sampling skips to be used, simplifying the implementation of this 
proposal.  It also helps to ensure robustness. The sample allocation will remain statistically valid 
if the actual number of Senate ballots in a particular state or the error rate differs slightly from 
what has been assumed.  

Table 1: Number of ballots to assure for stage 2 error by state 

 State 

Estimated 
Forms 2021/22 

Estimated 
Ballots assured 
(stage 2) 

Assurance 
Rate (1 in X 
ballots) 

95% confidence 
limit for maximum 
error rate 

99% confidence 
limit for maximum 
error rate 

NSW 

5,200,000 

VIC 

QLD 

SA 

WA 

4,130,000 

3,180,000 

1,200,000 

1,590,000 

1,733 

1,377 

1,272 

1,200 

1,272 

3,000 

3,000 

2,500 

1,000 

1,250 

2 

0.72% 

0.75% 

0.77% 

0.77% 

0.77% 

0.83% 

0.88% 

0.89% 

0.91% 

0.89% 

1 The 2019 assurance found zero errors in ACT, during stage 2 testing.  Consequently, there is over 95% 
confidence that the true ACT stage 2 error rate is less than the national stage 2 error rate. The national second 
stage error rate is applied to ACT in the interests of simplicity and to ensure that ACT is not under-allocated.


--- Page 3 ---

TAS 

NT 

ACT 

AUS 

387,000 

115,000 

293,000 

1,106 

958 

977 

350 

120 

300 

16,095,000 

9,895 

0.79% 

0.81% 

0.81% 

0.59% 

0.92% 

0.96% 

0.95% 

0.65% 

Testing conclusions 

Based on the observed error rates from the 2019 assurance and the sample sizes in each state 
the following statistical statements could be made. 

• 

If there is a 0.45% error rate found in the assurance sample, then the AEC can be 95% 
confident that nationally, there are less than 6 errors per 1,000 ballot papers in the 
Senate scanning process.  It is also true that if the true error rate in the population is 
0.45%, then the AEC can be 95% confident that the error rate estimated from the 
assurance sample will be less than 6 errors per 1,000 ballot papers. 

•  Similarly, there is 99% confidence that nationally there are less than 6.5 errors per 1,000 

• 

ballot papers. 
In any given state, there is 99% confidence that there are less than 10 errors per 1,000 
ballot papers. 

These statistical statements are illustrative only. They are based on the assumption of a true 
error rate of 0.45% in the population to give confidence on the size of the estimated error rate 
from the sample; or similarly on the assumption of an error rate of 0.45% in the assurance 
sample to give confidence in what the error rate is for the full population.  Final confidence 
intervals will depend on the actual error rates found during the 2021/22 assurance. 

Comparison with 2019 assurance approach 

It is instructive to compare the proposed assurance approach with the assurance approach 
previously implemented in 2019. 

First, it is noted that the total expected number of ballots to assurance (9,895) is slightly lower 
than in 2019 (10,400).  

Secondly, rather than assuring a constant number of ballots in each state, the proposed 
allocation is assurances of more ballots in the more populous states and less ballots in the less 
populous states.  

Increasing the number of ballots assured in the more populous states allows the proposed 
allocation to deliver a higher confidence in the national error rate, while assuring a smaller 
number of ballots. 

Third, it is specified to assure at a constant rate in each state, rather than a fixed total number of 
ballots. This is efficient to allow ballots to be assured while processing is ongoing, rather than 
having to wait for all ballots to be processed before commencing assurance. 

3


--- Page 4 ---

Practical implementation of assuring 

The AEC arranges senate ballots into bundles of 50. From a logistical perspective, it would be 
more efficient to first select a number of bundles and then select more than one ballot from each 
bundle. 

Furthermore, selecting bundles at a constant rate allows assurance to be undertaken while 
processing is ongoing – as it will not be necessary to have every bundle processed for assurance 
to commence. 

This is known as clustered sampling of the ballots.  Clustered samples can lead to lower 
accuracy if errors can also be clustered together, i.e. if errors are not evenly spread across all 
bundles.  We have suggested an approach that we believe balances the risk to accuracy from 
using a clustered sample with the benefits that it provides, i.e. reducing the number of bundles 
that need to be selected for the assurance sample.  The allocations provided in Table 1 have 
already allowed for some ‘slack’ by selecting more ballots than strictly necessary to obtain a 
precise national estimate of the stage 2 error. 

We propose the assurance selects a certain proportion of ‘bundles’ (e.g. 1 in every 300 bundles 
in NSW) and then to select 1/10 of all ballots in the bundle for stage 2 testing (so that overall 1 in 
every 3,000 ballots is selected in NSW). 

Once ballots have been selected for stage 2 testing, select 1 in every 10 of the stage 2 sample 
for stage 1 testing.  

If the sampling rate from Table 1 is adopted, then the process is described below in Table 2. 

Table 2: Number of forms to assure by state 

 State 

Estimated 
Forms 
2021/22 

Estimated 
Bundles 
2021/22 

NSW 

5,200,000 

104,000 

4,130,000 

82,600 

3,180,000 

63,600 

1,200,000 

24,000 

1,590,000 

31,800 

387,000 

115,000 

293,000 

7,740 

2,300 

5,860 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

AUS 

Assurance 
Rate  
(1 in X 
bundles) 

Estimated 
Bundles 
selected 

Estimated 
Ballots 
assured  
(stage 2) 

Assurance 
Rate  
(1 in X 
ballots) 

Estimated 
Ballots 
assured 
(stage 1) 

300 

300 

250 

100 

125 

35 

12 

30 

347 

275 

254 

240 

254 

221 

192 

195 

1,733 

1,377 

1,272 

1,200 

1,272 

1,106 

958 

977 

9,895 

3,000 

3,000 

2,500 

1,000 

1,250 

350 

120 

300 

173 

138 

127 

120 

127 

111 

96 

98 

989 

16,095,000 

321,900 

1,979 

4


--- Page 5 ---

Calculating the national error rate 

If an assurance approach uses a different sampling rate in different states, then in order to 
calculate the national error rate, it is  important to weight the number of errors found in each state 
by the state’s proportion of the national population. 

Table 3: 2019 assurance calculation of national error rate 

Total Senate 
ballots 2019  
(formal + informal) 

Proportion of 
national total 

Stage 2 
errors 
2019 

Stage 2 
sample 
2019 

Error 
rate 

Estimated 
total errors 

4,905,472 

3,896,236 

2,999,372 

1,134,556 

1,497,532 

365,272 

108,994 

276,651 

15,184,085  

32.3% 

25.7% 

19.8% 

7.5% 

9.9% 

2.4% 

0.7% 

1.8% 

7 

6 

6 

5 

4 

6 

2 

0 

1,300 

0.54% 

1,300 

0.46% 

1,300 

0.46% 

1,300 

0.38% 

1,300 

0.31% 

1,300 

0.46% 

1,300 

0.15% 

1,300 

0.00% 

26,414 

17,983 

13,843 

4,364 

4,608 

1,686 

168 

0 

0.45% 

69,065 

 State 

NSW 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

AUS 

The error rate in each state is estimated by dividing the number of errors in each state by the 
assurance sample size.  For example, in NSW the assurance for 7 errors from a sample of 
1,300, giving an error rate of 0.54%.  An error rate of 0.54% would mean that there is a total of 
26,414 errors from the full population of 4,905,472 votes in NSW. 

After calculating the estimated number of total errors in each state they can be added to produce 
an estimate of total number of errors in Australia.  This total is 69,065 based on the 2019 
assurance results. 

Dividing the estimate of 69,065 errors by the total national votes of 15,184,085 gives the 
estimated national error rate of 0.45%. 

An alternate approach to calculate this national error rate is to multiply the error rate in each state 
by the proportion of votes in that state.  This gives:  
(0.323 x 0.0054) + (0.257 x 0.0046) + (0.198 x 0.0046) + (0.075 x 0.0038) +  
(0.099 x 0.0031) + (0.024 x 0.0046) + (0.007 x 0.0015) + (0.018 x 0)  
= 0.0045.   

5


--- Page 6 ---

Appendix 

Table A1: Estimated senate forms by state for 2021/2022 Senate Election – source AEC 

State 

Estimated 
Senate Forms 

NSW 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

5,200,000 

4,130,000 

3,180,000 

1,200,000 

1,590,000 

387,000 

115,000 

293,000 

Table A2: number of stage 2 errors by state – 2019 Senate assurance – source AEC 

 State 

NSW 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

Stage 2 errors 
2019 assurance 

2019 Error rate 

7 

6 

6 

5 

4 

6 

2 

0 

0.54% 

0.46% 

0.46% 

0.38% 

0.31% 

0.46% 

0.15% 

Alternate allocations 

This section outlines various allocation options that were considered, that informed the final 
recommended approach. These options are presented for technical background and can be 
skipped. 

The allocation described in Table 1 represents the ABS’ main recommendation.  

6


--- Page 7 ---

Option A1: Allocation using a constant national sample rate 

The first option considered is to apply a constant assurance rate across each state nationally. 
This would differ from the assurance process from 2019, which assured a constant number of 
ballots (1,300) in each state as part of stage 2 testing.  

The advantages of applying a constant sample rate nationwide, is that it would allow the same 
assurance procedure to be applied in each state. Furthermore, the estimate of the national error 
rate would be easier to interpret as no weighting would be required. 

The disadvantage of applying a constant sample rate is that the smallest states would have 
relatively few ballots assured. This would result in a less confidence in the estimate of the state 
error rate. 

Sample allocations 

Table A3 shows the national level of accuracy associated with different sample sizes, while 
applying a constant sample rate nationally. 

Table A3: National sample size vs 95% margin of error of estimate 

Scenario 

National 
sample size 

1 in 
Rate 

One-sided 95% 
confidence level 

One-sided 99% 
confidence level 

A 

B 

C 

10,400 

1,548 

5,810 

2,770 

6,438 

2,500 

0.56% 

0.60% 

0.59% 

0.61% 

0.66% 

0.65% 

Scenario A represents the national sample size that was used for stage 2 testing as part of the 
2019 assurance. Scenario B represents the minimum national sample size to be 95% confident 
that the national error rate is less than 0.6%. 

From a practical perspective, it would make sense to use a larger sample size than this. 
Scenario C represents this, using a ‘round’ sample rate of 1 in 2,500 dwellings for each state.  

Table A4: Number of forms to assurance by state by scenario 

Estimated 
Forms 
2021/22 

5,200,000 

4,130,000 

3,180,000 

1,200,000 

1,590,000 

387,000 

115,000 

293,000 

 State 

NSW 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

Scenario A 

Scenario B 

Scenario C 

3,360 

2,669 

2,055 

775 

1,027 

250 

74 

189 

1,877 

1,491 

1,148 

433 

574 

140 

42 

106 

2,080 

1,652 

1,272 

480 

636 

155 

46 

117 

 TOTAL 

16,095,000 

10,400 

5,810 

6,438 

7


--- Page 8 ---

It is evident that if precisely estimating the national error rate is the key objective, than the 
sample rate required can be significantly lower than what was applied in 2019 (Scenario A). 
It is also clear that this approach results in a relatively small number of ballots being sampled in 
Tasmania, Northern Territory and Australian Capital Territory. 

Option A2: Allocation with maximum state margin of error (MOE) constraint 

A notable disadvantage of applying a fixed sampling rate across all states is that the number of 
ballots assured in the smaller states is low. This will result in wide confidence intervals for the 
state level estimates of proportion of errors in smaller states/territories. 

The following two allocations examine the number of ballots required to be assured in each state 
in order to be 95% or 99% confident that the true state level error rate would be less than 1%  

Table A5 : state assurance size required to be 95/99% confident that the true error rate &lt; 1% 

State one-sided confidence 
interval 

State sample 

National 95% confidence 
interval bound 

National 99% confidence 
interval bound 

95% 

413 

99% 

828 

0.71% 

0.64% 

0.82% 

0.71% 

Therefore, the state allocation to be 99% confident that the observed error rate is less than 1% in 
each state (assuming a 0.45% error rate in the population) is as in Table A6. 

Table A6 : State sample size and rate to be 99% confident that the assurance error rate is less than 1% 

 State 

Estimated 
Forms 
2021/22 

 State 
sample 

State 
sample rate 
(1 in X) 

NSW 

5,200,000 

VIC 

QLD 

SA 

WA 

TAS 

NT 

ACT 

4,130,000 

3,180,000 

1,200,000 

1,590,000 

387,000 

115,000 

293,000 

828 

828 

828 

828 

828 

828 

828 

828 

6,280 

4,988 

3,841 

1,449 

1,920 

467 

139 

354 

Table A6 was used as the basis behind the recommended option in Table 1. Additional sample 
was put into each state, in order to round off the sampling rates, and to allow a small buffer for 

8


--- Page 9 ---

error (e.g. if total votes in a state is smaller than expected; or if the true population error rate is 
higher than 0.45%). 

9


--- Page 10 ---

Glossary2 

Confidence Interval 

A confidence interval is an interval which has a known and controlled probability (generally 95% 
or 99%) to contain the true value. In the context of senate assurance, one-sided confidence limits 
are calculated for the stage 2 error rates, to determine the maximum error rate that could 
potentially occur, for the given level of confidence. 

Margin of Error (MoE) 

Margin of Error describes the distance from the population value that the assurance estimate is 
likely to be within, for a specified given level of confidence. For instance, at the 95% confidence 
level, the MoE indicates that there are about 19 chances in 20 that the estimate will differ from 
the population value (the figure obtained if all senate ballots had been assured) by less than the 
specified MoE. Equivalently it is one chance in 20 that the difference is greater than the specified 
MoE, i.e. outside the MoE. . 

Significance testing 

To determine whether a difference between two survey estimates is a real difference in the 
populations to which the estimates relate, or merely the product sampling variability, the 
statistical significance of the difference can be tested. The test is performed by calculating the 
standard error of the difference between two estimates and then dividing the actual difference by 
the standard error of the difference. If the result is greater than 1.96, there are 19 chances in 20 
that there is a real difference in the populations to which the estimates relate.  

Standard error 

The square root of the variance of the sampling distribution of a statistic (square root of variance 
of state or national error rate in the context of senate assurance) 

Variance 

The variance is the mean square deviation of the variable around the average value. It reflects 
the dispersion of the empirical values around its mean. 

2 Glossary definitions have been taken from ABS publications and The OECD Glossary of Statistical Terms 
 and modified to fit the context of senate assurance 

10</pre>
                </div>
                <!-- DEBUG: AI Overview tab-content rendered for inner PDF zip-1-0 -->
                <div class="tab-content" id="innerpdf-1-0-ai" data-persona-id="balanced">
                  <div class="ai-summary-markdown-content">
                    
                  </div>
                  
                  
                  <span class="ai-summary-label" data-summary-model="" data-summary-date="">
  AI Generated <i class="info-icon">?</i>
</span>
                </div>
              </div>
            
          </section>
        
      
    
  </main>
</div>

    </main>
    <footer>
        <!-- todo: link to AEC foi log original page or something -->
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="/static/lunr.min.js"></script>
    <script src="/static/search.js"></script>
    <script>
      window.PERSONAS_LIST = ["balanced", "left_leaning", "right_leaning", "government_skeptic", "government_apologist", "highly_critical"];
      window.DEFAULT_PERSONA = 'balanced';
    </script>
    <script src="/static/general_ui.js" defer></script>
    
<script type="application/json" id="current-foi-data">
  {"id": "LEX2979", "title": "FOI Request LEX2979", "date": "2022", "year": 2022, "files": [{"type": "pdf", "output_file_path": "/downloaded_originals/lex2979-schedule.pdf", "content_files": [], "extracted_text_path": "/extracted_texts/LEX2979_lex2979-schedule.txt", "ai_summaries": {"balanced": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}, "left_leaning": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}, "right_leaning": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}, "government_skeptic": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}, "government_apologist": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}, "highly_critical": {"needs_summary": true, "source_hash": "ca646894d2511015e68135e25374626963155f2c5e54f95c04450bda83f5ada2"}}, "original_url": "https://www.aec.gov.au/information-access/foi/2022/files/lex2979-schedule.pdf", "link_text": "FOI Request LEX2979, Schedule of Released Documents [PDF 546KB]", "server_filename": "lex2979-schedule.pdf", "extracted_text": "\n\n--- Page 1 ---\n\nRequest for: \n\nFOI REQUEST NO. LEX2979 \n\n\uf0b7 \n\n\u201cThe document specifying the methodology to be used for the ballot paper sampling process in the audit of Senate ballot papers. Not the process \noutline published here: https://www.aec.gov.au/About_AEC/cea-notices/files/2022/s273AC-senate-assurancemethodology-fe2022.pdf but the \ndocument referred to in the above document as \"advice from the Australian Bureau of Statistics\" and \"ABS' guidance for calculating, analysing and \nreporting the statistical conclusions that can be drawn.\" \n\nDoc No.  Description \n\nABS Advice to AEC on sampling methodology \n\nSCHEDULE OF RETRIEVED DOCUMENTS"}, {"type": "zip", "output_file_path": "/downloaded_originals/lex2979.zip", "content_files": [{"type": "pdf", "output_file_path": "/downloaded_originals/LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf", "content_files": [], "extracted_text_path": "/extracted_texts/LEX2979_LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.txt", "ai_summaries": {"balanced": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}, "left_leaning": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}, "right_leaning": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}, "government_skeptic": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}, "government_apologist": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}, "highly_critical": {"needs_summary": true, "source_hash": "e7cbe69898f5d5890573bf6a054314aa46d64a8cfd1dee915a951fb8c9b0f535"}}, "filename": "LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf", "download_path": "/foi_assets/LEX2979/LEX2979 Relevant Document - ABS Advice to AEC on sampling methodology.pdf", "extracted_text": "\n\n--- Page 1 ---\n\nABS advice to AEC on sampling methodology \n\nExecutive Summary \n\nThe Australian Electoral Commission (AEC) has requested advice from the ABS to determine the \nnumber of ballots for assurance as part of the elections for the Australian Senate. The number of \nballots that are manually checked for errors should be sufficient to demonstrate with a high level \nof confidence that the possible national error rate is low. \n\nThe ABS recommends that Senate ballots should be assured at the following rate: \n\n\u2022  1 in 3,000 ballots in New South Wales and Victoria; \n\u2022  1 in 2,500 ballots in Queensland; \n\u2022  1 in 1,250 ballots in Western Australia; \n\u2022  1 in 1,000 ballots in South Australia; \n\u2022  1 in 350 ballots in Tasmania; \n\u2022  1 in 300 ballots in Australian Capital Territory; \n\u2022  1 in 120 ballots in Northern Territory. \n\nBased on these rates, it is estimated that 9,895 ballots will be assured nationally for the 2021/22 \nSenate election. A state breakdown is provided in Table 1: \n\nThis assurance approach will provide a high level of confidence in confirming that the national \nerror rate and error rates in each of the states and territories is low. \n\nIn comparison with the internal AEC assurance approach implemented in 2019, the proposed \nallocation delivers a higher confidence in the national error rate, while requiring fewer ballots to \nbe assured. The proposed approach also allows ballot assurance to be undertaken while \nprocessing. This is helpful to speed up the assurance. \n\nBackground \n\nThe Senate assurance process implements two stages of ballot testing. The first stage of testing \nchecks that the scanned image matches the physical ballot paper. The second stage checks that \nthe scanned image of the ballot paper matches the extracted data file, i.e. that the preferences \nfrom the scanned image match the datafile that is used to run the preference allocation process. \n\nAn assurance of the 2019 Senate election found no errors during the first stage at ballot testing. \nThe national estimate of the proportion of errors during the second stage of ballot testing is \n0.45%. The calculation of the national error rate is discussed here. \n\n1\n\n\n--- Page 2 ---\n\nThe emphasis of this report is to determine an appropriate allocation to assurance for stage 2 \nerrors. Given that no stage 1 errors were detected as part of the 2019 assurance from a sample \nof 1,368, it is evident that the true stage 1 error rate is very low. For the purposes of stage 1 \ntesting, it should be sufficient to assurance 1 in 10 of the ballots selected for stage 2 testing. The \npractical implementation is discussed here. \n\nRecommended Allocation \n\nThis section details the recommended allocation and diagnostics associated with it \nAlternate allocations were considered and informed the final recommended allocation. See \nAppendix. \n\nThe allocation utilised the following assumptions. \n\n\u2022  While the 2019 assurance indicated that the prevalence of stage 2 errors differed by \nstate, the difference between the state and national proportion of errors was not \nstatistically significant, with the exception of the ACT, which had no errors detected.1 \nTherefore, the calculated national stage 2 error rate of 0.45% was assumed in each \nstate.  \n\n\u2022  An estimate of 16.095 million Senate forms nationally for the 2021/22 election. The \n\ndistribution of form by state as provided by the AEC \u2013 see Table A1. \n\nThe main criterion implemented for designing the target number of ballots to assurance by state \nwas to have 99% confidence that the observed error rate in the sample for each state will be less \nthan 1%, assuming that an error rate of 0.45% (as estimated in 2019) applies for the full \npopulation of senate votes. \n\nThe minimum sample size to achieve this is to select 828 ballots in each state and territory \u2013 see \nAppendix for details. \n\nThe recommended allocation places sample beyond this minimum value into each state. This is \na conservative approach to ensure we have enough sample to meet the accuracy targets, and it \nproduces round numbers for the sampling skips to be used, simplifying the implementation of this \nproposal.  It also helps to ensure robustness. The sample allocation will remain statistically valid \nif the actual number of Senate ballots in a particular state or the error rate differs slightly from \nwhat has been assumed.  \n\nTable 1: Number of ballots to assure for stage 2 error by state \n\n State \n\nEstimated \nForms 2021/22 \n\nEstimated \nBallots assured \n(stage 2) \n\nAssurance \nRate (1 in X \nballots) \n\n95% confidence \nlimit for maximum \nerror rate \n\n99% confidence \nlimit for maximum \nerror rate \n\nNSW \n\n5,200,000 \n\nVIC \n\nQLD \n\nSA \n\nWA \n\n4,130,000 \n\n3,180,000 \n\n1,200,000 \n\n1,590,000 \n\n1,733 \n\n1,377 \n\n1,272 \n\n1,200 \n\n1,272 \n\n3,000 \n\n3,000 \n\n2,500 \n\n1,000 \n\n1,250 \n\n2 \n\n0.72% \n\n0.75% \n\n0.77% \n\n0.77% \n\n0.77% \n\n0.83% \n\n0.88% \n\n0.89% \n\n0.91% \n\n0.89% \n\n1 The 2019 assurance found zero errors in ACT, during stage 2 testing.  Consequently, there is over 95% \nconfidence that the true ACT stage 2 error rate is less than the national stage 2 error rate. The national second \nstage error rate is applied to ACT in the interests of simplicity and to ensure that ACT is not under-allocated.\n\n\n--- Page 3 ---\n\nTAS \n\nNT \n\nACT \n\nAUS \n\n387,000 \n\n115,000 \n\n293,000 \n\n1,106 \n\n958 \n\n977 \n\n350 \n\n120 \n\n300 \n\n16,095,000 \n\n9,895 \n\n0.79% \n\n0.81% \n\n0.81% \n\n0.59% \n\n0.92% \n\n0.96% \n\n0.95% \n\n0.65% \n\nTesting conclusions \n\nBased on the observed error rates from the 2019 assurance and the sample sizes in each state \nthe following statistical statements could be made. \n\n\u2022 \n\nIf there is a 0.45% error rate found in the assurance sample, then the AEC can be 95% \nconfident that nationally, there are less than 6 errors per 1,000 ballot papers in the \nSenate scanning process.  It is also true that if the true error rate in the population is \n0.45%, then the AEC can be 95% confident that the error rate estimated from the \nassurance sample will be less than 6 errors per 1,000 ballot papers. \n\n\u2022  Similarly, there is 99% confidence that nationally there are less than 6.5 errors per 1,000 \n\n\u2022 \n\nballot papers. \nIn any given state, there is 99% confidence that there are less than 10 errors per 1,000 \nballot papers. \n\nThese statistical statements are illustrative only. They are based on the assumption of a true \nerror rate of 0.45% in the population to give confidence on the size of the estimated error rate \nfrom the sample; or similarly on the assumption of an error rate of 0.45% in the assurance \nsample to give confidence in what the error rate is for the full population.  Final confidence \nintervals will depend on the actual error rates found during the 2021/22 assurance. \n\nComparison with 2019 assurance approach \n\nIt is instructive to compare the proposed assurance approach with the assurance approach \npreviously implemented in 2019. \n\nFirst, it is noted that the total expected number of ballots to assurance (9,895) is slightly lower \nthan in 2019 (10,400).  \n\nSecondly, rather than assuring a constant number of ballots in each state, the proposed \nallocation is assurances of more ballots in the more populous states and less ballots in the less \npopulous states.  \n\nIncreasing the number of ballots assured in the more populous states allows the proposed \nallocation to deliver a higher confidence in the national error rate, while assuring a smaller \nnumber of ballots. \n\nThird, it is specified to assure at a constant rate in each state, rather than a fixed total number of \nballots. This is efficient to allow ballots to be assured while processing is ongoing, rather than \nhaving to wait for all ballots to be processed before commencing assurance. \n\n3\n\n\n--- Page 4 ---\n\nPractical implementation of assuring \n\nThe AEC arranges senate ballots into bundles of 50. From a logistical perspective, it would be \nmore efficient to first select a number of bundles and then select more than one ballot from each \nbundle. \n\nFurthermore, selecting bundles at a constant rate allows assurance to be undertaken while \nprocessing is ongoing \u2013 as it will not be necessary to have every bundle processed for assurance \nto commence. \n\nThis is known as clustered sampling of the ballots.  Clustered samples can lead to lower \naccuracy if errors can also be clustered together, i.e. if errors are not evenly spread across all \nbundles.  We have suggested an approach that we believe balances the risk to accuracy from \nusing a clustered sample with the benefits that it provides, i.e. reducing the number of bundles \nthat need to be selected for the assurance sample.  The allocations provided in Table 1 have \nalready allowed for some \u2018slack\u2019 by selecting more ballots than strictly necessary to obtain a \nprecise national estimate of the stage 2 error. \n\nWe propose the assurance selects a certain proportion of \u2018bundles\u2019 (e.g. 1 in every 300 bundles \nin NSW) and then to select 1/10 of all ballots in the bundle for stage 2 testing (so that overall 1 in \nevery 3,000 ballots is selected in NSW). \n\nOnce ballots have been selected for stage 2 testing, select 1 in every 10 of the stage 2 sample \nfor stage 1 testing.  \n\nIf the sampling rate from Table 1 is adopted, then the process is described below in Table 2. \n\nTable 2: Number of forms to assure by state \n\n State \n\nEstimated \nForms \n2021/22 \n\nEstimated \nBundles \n2021/22 \n\nNSW \n\n5,200,000 \n\n104,000 \n\n4,130,000 \n\n82,600 \n\n3,180,000 \n\n63,600 \n\n1,200,000 \n\n24,000 \n\n1,590,000 \n\n31,800 \n\n387,000 \n\n115,000 \n\n293,000 \n\n7,740 \n\n2,300 \n\n5,860 \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\nAUS \n\nAssurance \nRate  \n(1 in X \nbundles) \n\nEstimated \nBundles \nselected \n\nEstimated \nBallots \nassured  \n(stage 2) \n\nAssurance \nRate  \n(1 in X \nballots) \n\nEstimated \nBallots \nassured \n(stage 1) \n\n300 \n\n300 \n\n250 \n\n100 \n\n125 \n\n35 \n\n12 \n\n30 \n\n347 \n\n275 \n\n254 \n\n240 \n\n254 \n\n221 \n\n192 \n\n195 \n\n1,733 \n\n1,377 \n\n1,272 \n\n1,200 \n\n1,272 \n\n1,106 \n\n958 \n\n977 \n\n9,895 \n\n3,000 \n\n3,000 \n\n2,500 \n\n1,000 \n\n1,250 \n\n350 \n\n120 \n\n300 \n\n173 \n\n138 \n\n127 \n\n120 \n\n127 \n\n111 \n\n96 \n\n98 \n\n989 \n\n16,095,000 \n\n321,900 \n\n1,979 \n\n4\n\n\n--- Page 5 ---\n\nCalculating the national error rate \n\nIf an assurance approach uses a different sampling rate in different states, then in order to \ncalculate the national error rate, it is  important to weight the number of errors found in each state \nby the state\u2019s proportion of the national population. \n\nTable 3: 2019 assurance calculation of national error rate \n\nTotal Senate \nballots 2019  \n(formal + informal) \n\nProportion of \nnational total \n\nStage 2 \nerrors \n2019 \n\nStage 2 \nsample \n2019 \n\nError \nrate \n\nEstimated \ntotal errors \n\n4,905,472 \n\n3,896,236 \n\n2,999,372 \n\n1,134,556 \n\n1,497,532 \n\n365,272 \n\n108,994 \n\n276,651 \n\n15,184,085  \n\n32.3% \n\n25.7% \n\n19.8% \n\n7.5% \n\n9.9% \n\n2.4% \n\n0.7% \n\n1.8% \n\n7 \n\n6 \n\n6 \n\n5 \n\n4 \n\n6 \n\n2 \n\n0 \n\n1,300 \n\n0.54% \n\n1,300 \n\n0.46% \n\n1,300 \n\n0.46% \n\n1,300 \n\n0.38% \n\n1,300 \n\n0.31% \n\n1,300 \n\n0.46% \n\n1,300 \n\n0.15% \n\n1,300 \n\n0.00% \n\n26,414 \n\n17,983 \n\n13,843 \n\n4,364 \n\n4,608 \n\n1,686 \n\n168 \n\n0 \n\n0.45% \n\n69,065 \n\n State \n\nNSW \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\nAUS \n\nThe error rate in each state is estimated by dividing the number of errors in each state by the \nassurance sample size.  For example, in NSW the assurance for 7 errors from a sample of \n1,300, giving an error rate of 0.54%.  An error rate of 0.54% would mean that there is a total of \n26,414 errors from the full population of 4,905,472 votes in NSW. \n\nAfter calculating the estimated number of total errors in each state they can be added to produce \nan estimate of total number of errors in Australia.  This total is 69,065 based on the 2019 \nassurance results. \n\nDividing the estimate of 69,065 errors by the total national votes of 15,184,085 gives the \nestimated national error rate of 0.45%. \n\nAn alternate approach to calculate this national error rate is to multiply the error rate in each state \nby the proportion of votes in that state.  This gives:  \n(0.323 x 0.0054) + (0.257 x 0.0046) + (0.198 x 0.0046) + (0.075 x 0.0038) +  \n(0.099 x 0.0031) + (0.024 x 0.0046) + (0.007 x 0.0015) + (0.018 x 0)  \n= 0.0045.   \n\n5\n\n\n--- Page 6 ---\n\nAppendix \n\nTable A1: Estimated senate forms by state for 2021/2022 Senate Election \u2013 source AEC \n\nState \n\nEstimated \nSenate Forms \n\nNSW \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\n5,200,000 \n\n4,130,000 \n\n3,180,000 \n\n1,200,000 \n\n1,590,000 \n\n387,000 \n\n115,000 \n\n293,000 \n\nTable A2: number of stage 2 errors by state \u2013 2019 Senate assurance \u2013 source AEC \n\n State \n\nNSW \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\nStage 2 errors \n2019 assurance \n\n2019 Error rate \n\n7 \n\n6 \n\n6 \n\n5 \n\n4 \n\n6 \n\n2 \n\n0 \n\n0.54% \n\n0.46% \n\n0.46% \n\n0.38% \n\n0.31% \n\n0.46% \n\n0.15% \n\nAlternate allocations \n\nThis section outlines various allocation options that were considered, that informed the final \nrecommended approach. These options are presented for technical background and can be \nskipped. \n\nThe allocation described in Table 1 represents the ABS\u2019 main recommendation.  \n\n6\n\n\n--- Page 7 ---\n\nOption A1: Allocation using a constant national sample rate \n\nThe first option considered is to apply a constant assurance rate across each state nationally. \nThis would differ from the assurance process from 2019, which assured a constant number of \nballots (1,300) in each state as part of stage 2 testing.  \n\nThe advantages of applying a constant sample rate nationwide, is that it would allow the same \nassurance procedure to be applied in each state. Furthermore, the estimate of the national error \nrate would be easier to interpret as no weighting would be required. \n\nThe disadvantage of applying a constant sample rate is that the smallest states would have \nrelatively few ballots assured. This would result in a less confidence in the estimate of the state \nerror rate. \n\nSample allocations \n\nTable A3 shows the national level of accuracy associated with different sample sizes, while \napplying a constant sample rate nationally. \n\nTable A3: National sample size vs 95% margin of error of estimate \n\nScenario \n\nNational \nsample size \n\n1 in \nRate \n\nOne-sided 95% \nconfidence level \n\nOne-sided 99% \nconfidence level \n\nA \n\nB \n\nC \n\n10,400 \n\n1,548 \n\n5,810 \n\n2,770 \n\n6,438 \n\n2,500 \n\n0.56% \n\n0.60% \n\n0.59% \n\n0.61% \n\n0.66% \n\n0.65% \n\nScenario A represents the national sample size that was used for stage 2 testing as part of the \n2019 assurance. Scenario B represents the minimum national sample size to be 95% confident \nthat the national error rate is less than 0.6%. \n\nFrom a practical perspective, it would make sense to use a larger sample size than this. \nScenario C represents this, using a \u2018round\u2019 sample rate of 1 in 2,500 dwellings for each state.  \n\nTable A4: Number of forms to assurance by state by scenario \n\nEstimated \nForms \n2021/22 \n\n5,200,000 \n\n4,130,000 \n\n3,180,000 \n\n1,200,000 \n\n1,590,000 \n\n387,000 \n\n115,000 \n\n293,000 \n\n State \n\nNSW \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\nScenario A \n\nScenario B \n\nScenario C \n\n3,360 \n\n2,669 \n\n2,055 \n\n775 \n\n1,027 \n\n250 \n\n74 \n\n189 \n\n1,877 \n\n1,491 \n\n1,148 \n\n433 \n\n574 \n\n140 \n\n42 \n\n106 \n\n2,080 \n\n1,652 \n\n1,272 \n\n480 \n\n636 \n\n155 \n\n46 \n\n117 \n\n TOTAL \n\n16,095,000 \n\n10,400 \n\n5,810 \n\n6,438 \n\n7\n\n\n--- Page 8 ---\n\nIt is evident that if precisely estimating the national error rate is the key objective, than the \nsample rate required can be significantly lower than what was applied in 2019 (Scenario A). \nIt is also clear that this approach results in a relatively small number of ballots being sampled in \nTasmania, Northern Territory and Australian Capital Territory. \n\nOption A2: Allocation with maximum state margin of error (MOE) constraint \n\nA notable disadvantage of applying a fixed sampling rate across all states is that the number of \nballots assured in the smaller states is low. This will result in wide confidence intervals for the \nstate level estimates of proportion of errors in smaller states/territories. \n\nThe following two allocations examine the number of ballots required to be assured in each state \nin order to be 95% or 99% confident that the true state level error rate would be less than 1%  \n\nTable A5 : state assurance size required to be 95/99% confident that the true error rate < 1% \n\nState one-sided confidence \ninterval \n\nState sample \n\nNational 95% confidence \ninterval bound \n\nNational 99% confidence \ninterval bound \n\n95% \n\n413 \n\n99% \n\n828 \n\n0.71% \n\n0.64% \n\n0.82% \n\n0.71% \n\nTherefore, the state allocation to be 99% confident that the observed error rate is less than 1% in \neach state (assuming a 0.45% error rate in the population) is as in Table A6. \n\nTable A6 : State sample size and rate to be 99% confident that the assurance error rate is less than 1% \n\n State \n\nEstimated \nForms \n2021/22 \n\n State \nsample \n\nState \nsample rate \n(1 in X) \n\nNSW \n\n5,200,000 \n\nVIC \n\nQLD \n\nSA \n\nWA \n\nTAS \n\nNT \n\nACT \n\n4,130,000 \n\n3,180,000 \n\n1,200,000 \n\n1,590,000 \n\n387,000 \n\n115,000 \n\n293,000 \n\n828 \n\n828 \n\n828 \n\n828 \n\n828 \n\n828 \n\n828 \n\n828 \n\n6,280 \n\n4,988 \n\n3,841 \n\n1,449 \n\n1,920 \n\n467 \n\n139 \n\n354 \n\nTable A6 was used as the basis behind the recommended option in Table 1. Additional sample \nwas put into each state, in order to round off the sampling rates, and to allow a small buffer for \n\n8\n\n\n--- Page 9 ---\n\nerror (e.g. if total votes in a state is smaller than expected; or if the true population error rate is \nhigher than 0.45%). \n\n9\n\n\n--- Page 10 ---\n\nGlossary2 \n\nConfidence Interval \n\nA confidence interval is an interval which has a known and controlled probability (generally 95% \nor 99%) to contain the true value. In the context of senate assurance, one-sided confidence limits \nare calculated for the stage 2 error rates, to determine the maximum error rate that could \npotentially occur, for the given level of confidence. \n\nMargin of Error (MoE) \n\nMargin of Error describes the distance from the population value that the assurance estimate is \nlikely to be within, for a specified given level of confidence. For instance, at the 95% confidence \nlevel, the MoE indicates that there are about 19 chances in 20 that the estimate will differ from \nthe population value (the figure obtained if all senate ballots had been assured) by less than the \nspecified MoE. Equivalently it is one chance in 20 that the difference is greater than the specified \nMoE, i.e. outside the MoE. . \n\nSignificance testing \n\nTo determine whether a difference between two survey estimates is a real difference in the \npopulations to which the estimates relate, or merely the product sampling variability, the \nstatistical significance of the difference can be tested. The test is performed by calculating the \nstandard error of the difference between two estimates and then dividing the actual difference by \nthe standard error of the difference. If the result is greater than 1.96, there are 19 chances in 20 \nthat there is a real difference in the populations to which the estimates relate.  \n\nStandard error \n\nThe square root of the variance of the sampling distribution of a statistic (square root of variance \nof state or national error rate in the context of senate assurance) \n\nVariance \n\nThe variance is the mean square deviation of the variable around the average value. It reflects \nthe dispersion of the empirical values around its mean. \n\n2 Glossary definitions have been taken from ABS publications and The OECD Glossary of Statistical Terms \n and modified to fit the context of senate assurance \n\n10"}], "extracted_text_path": "", "ai_summaries": {"balanced": null, "left_leaning": null, "right_leaning": null, "government_skeptic": null, "government_apologist": null, "highly_critical": null}, "original_url": "https://www.aec.gov.au/information-access/foi/2022/files/lex2979.zip", "link_text": "LEX2979 documents [ZIP 350KB]", "server_filename": "lex2979.zip"}], "ai_summaries": {"balanced": {"overall": {"text": "## FOI Request Summary: LEX2979 - Senate Ballot Paper Sampling Methodology\n\n### Main Purpose of the FOI Request\n\nThe FOI request, identified as LEX2979, sought to obtain the specific document detailing the methodology for the ballot paper sampling process used in the audit of Senate ballot papers. It specifically requested the \"advice from the Australian Bureau of Statistics\" (ABS) and their \"guidance for calculating, analysing and reporting the statistical conclusions that can be drawn,\" explicitly excluding any general process outlines already published by the AEC.\n\n### Documents from the FOI Request\n\nThe request resulted in the release of one document:\n*   **\"ABS Advice to AEC on sampling methodology\"**\n\n### Main Content from the FOI Request Documents\n\nThe released document, \"ABS Advice to AEC on sampling methodology,\" outlines the statistical methodology recommended by the ABS to the Australian Electoral Commission (AEC) for assuring the accuracy of Senate ballot paper processing.\n\nKey content includes:\n\n*   **Objective:** To determine the optimal number of ballots to manually check to ensure a high level of confidence that the national error rate in the Senate ballot scanning and data extraction process is low. The primary focus is on \"Stage 2 errors\" (matching scanned images to extracted data), given that \"Stage 1 errors\" (scanned images matching physical ballots) were found to be negligible in previous audits.\n*   **Recommended Sampling Rates:** The ABS recommends specific assurance rates per state/territory for Stage 2 testing, which vary based on the estimated number of Senate forms. Examples include:\n    *   1 in 3,000 ballots in New South Wales and Victoria.\n    *   1 in 120 ballots in the Northern Territory.\n    *   This approach is estimated to involve checking 9,895 ballots nationally for the 2021/22 Senate election.\n*   **Confidence Targets:** The methodology aims to achieve 99% confidence that the observed error rate in the sample for each state will be less than 1%, assuming a true population error rate of 0.45% (derived from the 2019 assurance). This translates to a 99% confidence that the national error rate is less than 6.5 errors per 1,000 ballot papers and less than 10 errors per 1,000 in any given state.\n*   **Efficiency Improvements:** The proposed methodology is noted to be more efficient than the 2019 internal AEC approach, requiring fewer total ballots for assurance while providing higher confidence in the national error rate. It also allows assurance to occur concurrently with ongoing ballot processing.\n*   **Practical Implementation:** The document details a \"clustered sampling\" approach for practical implementation. This involves:\n    *   Selecting a proportion of ballot \"bundles\" (each containing 50 ballots) at a constant rate per state (e.g., 1 in every 300 bundles in NSW).\n    *   Then, selecting 1 in 10 of the ballots within the chosen bundles for Stage 2 testing.\n    *   Subsequently, selecting 1 in 10 of the Stage 2 sample for Stage 1 testing.\n*   **National Error Rate Calculation:** Guidance is provided on how to calculate the national error rate when different sampling rates are applied across states, emphasizing the need to weight state-level errors by their proportion of the national population.\n*   **Alternate Options Considered:** The document also discusses alternative sampling allocation strategies that were evaluated (e.g., constant national sample rate, maximum state margin of error constraint), explaining the rationale for selecting the final recommended approach for its robustness and practical benefits.\n\nIn essence, the released document provides the comprehensive statistical and practical guide developed by the ABS for the AEC's Senate ballot paper assurance process, detailing sample sizes, confidence levels, and implementation methods.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:14:26.279795", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__balanced__20250622T141426.json", "output_tokens": 811, "prompt_tokens": 6580, "total_tokens": 9525, "summary_length": 3856}, "short_index": {"text": "FOI request LEX2979 specifically sought the Australian Bureau of Statistics' (ABS) methodology for sampling Senate ballot papers to audit their processing accuracy. The released document, \"ABS Advice to AEC on sampling methodology,\" details the statistical approach recommended to the Australian Electoral Commission (AEC) to assure high confidence in the accuracy of ballot scanning and data extraction, primarily targeting \"Stage 2 errors.\" It specifies varying sampling rates per state/territory (e.g., 1 in 3,000 in NSW, 1 in 120 in NT), aiming for 99% confidence that the national error rate is low (e.g., less than 6.5 errors per 1,000 ballot papers). The methodology, deemed more efficient than previous approaches, uses a \"clustered sampling\" technique, selecting bundles of ballots and then individual ballots within them, and provides guidance for calculating the national error rate while also discussing alternative options considered.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:14:31.292707", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__balanced__20250622T141431.json", "output_tokens": 199, "prompt_tokens": 853, "total_tokens": 1467, "summary_length": 947}}, "left_leaning": {"overall": {"text": "The provided FOI documents detail the Australian Bureau of Statistics (ABS) advice to the Australian Electoral Commission (AEC) on the statistical methodology for auditing Senate ballot papers. This technical advice focuses on determining the sample size and assurance rates for checking the accuracy of scanned ballot images against physical papers and the extraction of voter preferences.\n\nFrom a politically left-leaning perspective, the documents reveal several points concerning social justice and civil liberties, while issues related to environmental impact, wealth distribution, and corporate influence are not directly addressed by the technical scope of this methodology.\n\n**Alignment with Progressive Values:**\n\n1.  **Commitment to Electoral Integrity and Civil Liberties:** The core purpose of the ABS advice is to establish a statistically robust method to verify the accuracy of the Senate vote count. This directly aligns with the progressive value of protecting the civil liberty of every citizen to have their vote accurately recorded and counted. The aim for a \"high level of confidence\" (99%) that error rates are \"low\" (under 1% observed) demonstrates a commitment to maintaining public trust in democratic processes.\n2.  **Transparency and Accountability:** The very fact that this detailed methodology is accessible through an FOI request highlights a degree of transparency in government operations. This openness, where the public can scrutinize the statistical underpinnings of electoral audits, is crucial for holding government agencies accountable and fostering an informed citizenry, a cornerstone of progressive governance.\n3.  **Data-Driven Decision Making:** The reliance on the ABS, a non-political statistical authority, for expert advice underscores a commitment to objective, data-driven methodologies for election assurance. This approach prioritizes scientific rigor over arbitrary or politically motivated decisions, which enhances fairness and reduces opportunities for manipulation or bias in the electoral process.\n\n**Deviations from Progressive Values / Areas for Scrutiny:**\n\n1.  **Tolerance for Error and Social Justice Implications:** While the document frames a 0.45% national error rate for Stage 2 (preference extraction) as \"low\" and aims to confirm it, a progressive analysis might question the acceptability of such a figure. The 2019 assurance estimated 69,065 errors nationally. Even statistically \"low,\" errors in tens of thousands of ballot papers, particularly in preference allocation, could potentially alter outcomes in very close elections or disproportionately impact the representation of smaller parties, independent candidates, or specific demographics. From a social justice perspective, every vote, and every preference, should ideally be counted without error to ensure precise democratic representation. The question arises whether efficiency (fewer ballots assured than in 2019) is being prioritized over absolute accuracy, especially if errors are not truly random but systematically affect certain voting patterns or regions.\n2.  **Potential Risks of Clustered Sampling:** The proposed \"clustered sampling\" method, while acknowledged as more efficient, carries the stated risk that \"Clustered samples can lead to lower accuracy if errors can also be clustered together.\" While the ABS states this risk has been balanced, a progressive lens would demand more robust transparency on the specific assessments and mitigation strategies for this risk. If, for example, a technical malfunction or human error affects an entire batch of ballots, concentrated errors could be missed, potentially skewing results in a specific area, which could have implications for the fairness of representation.\n3.  **Disparities in State Assurance Rates:** The recommended assurance rates vary significantly by state/territory (e.g., 1 in 3,000 in NSW/VIC vs. 1 in 120 in NT). While statistically justified for achieving confidence in smaller populations, it means a ballot in the Northern Territory is proportionally much more likely to be checked than one in New South Wales. While this ensures statistical validity across smaller populations, it highlights an unequal level of *direct scrutiny* per vote across different regions, raising a subtle question about equitable treatment, even if technically sound.\n4.  **National vs. State-Level Focus:** The new allocation explicitly aims for \"higher confidence in the national error rate\" with fewer total ballots. While efficient, a progressive perspective might question if this national optimization sufficiently prioritizes absolute accuracy and confidence *within each state*, particularly given observed differences in 2019 state-level error rates (e.g., ACT had zero errors). Applying a national average error rate assumption (0.45%) to all states \"in the interests of simplicity\" could be seen as an averaging that potentially masks or underplays localized issues or anomalies crucial for local electoral integrity.\n\nIn conclusion, these FOI documents demonstrate a technocratic commitment to ensuring electoral integrity through statistical sampling, aligning with progressive values of transparency and data-driven governance. However, they also prompt critical questions from a left-leaning perspective regarding the acceptable tolerance for electoral errors, the potential trade-offs between efficiency and absolute accuracy, and how statistical methods impact the fundamental right to a perfectly counted vote across all communities.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:14:51.354347", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__left_leaning__20250622T141451.json", "output_tokens": 1013, "prompt_tokens": 6571, "total_tokens": 9389, "summary_length": 5547}, "short_index": {"text": "From a left-leaning perspective, the ABS advice for auditing Senate ballots demonstrates a commendable commitment to electoral integrity, transparency, and data-driven governance, aligning with core progressive values by ensuring a statistically robust vote count. However, critical scrutiny reveals concerns that the inherent tolerance for error, even at a \"low\" 0.45% national rate potentially affecting tens of thousands of ballots, prioritizes statistical efficiency over the absolute accuracy required to ensure every vote and preference is perfectly counted. This approach, alongside the risks of clustered sampling and disparities in state-level scrutiny, raises questions about potential uneven impacts on representation, particularly for close contests or smaller demographics, highlighting the ongoing need for vigilance to guarantee truly equitable and precise democratic outcomes.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:14:58.833224", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__left_leaning__20250622T141458.json", "output_tokens": 146, "prompt_tokens": 1062, "total_tokens": 2308, "summary_length": 892}}, "right_leaning": {"overall": {"text": "The FOI documents detail the Australian Bureau of Statistics\u2019 (ABS) advice to the Australian Electoral Commission (AEC) on the statistical methodology for auditing Senate ballot papers, specifically focusing on the accuracy of scanning and data extraction processes. From a right-leaning analytical perspective, several key aspects align positively with conservative principles:\n\n**Economic Efficiency and Fiscal Responsibility:**\nThe new assurance methodology is highlighted as requiring **fewer ballots to be manually checked (9,895 vs. 10,400 in 2019) while simultaneously delivering higher confidence in the national error rate.** This represents a direct gain in **economic efficiency**, achieving a better outcome with fewer resources. The ability to conduct assurance \"while processing is ongoing\" further contributes to efficiency by streamlining operations and potentially reducing labor costs associated with delays or separate audit phases. The adoption of \"clustered sampling\" for \"logistical efficiency\" also points to a pragmatic effort to optimize resource allocation, provided the acknowledged risk to accuracy from error clustering is genuinely offset by the built-in \"slack\" in the sample, as stated. This focus on optimizing output (confidence) relative to input (ballots assured, processing time) demonstrates a commitment to **fiscal responsibility** by ensuring taxpayer funds are used effectively for an essential government function.\n\n**Individual Liberty:**\nThe core purpose of this methodology is to ensure a **low error rate** in the counting of Senate ballots. By striving for a high degree of confidence (e.g., 99% confidence that the observed error rate in any state will be less than 1%), the process aims to ensure that the outcome of elections accurately reflects the will of the voters. This is fundamental to **individual liberty**, as the integrity of the vote directly underpins the democratic process and the legitimate derivation of government power from the consent of the governed. A trustworthy electoral system is vital for citizens to have confidence that their individual vote contributes meaningfully to the selection of their representatives, thereby upholding their democratic rights.\n\n**Limited Government:**\nThe documents illustrate an example of government agencies operating within their defined scope and seeking to perform their functions transparently and competently. The AEC, responsible for elections, consults with the ABS, an independent statistical authority, to ensure methodological rigor. This reliance on expert advice and the use of statistically sound practices to ensure accuracy, rather than arbitrary or opaque processes, aligns with the principle of **limited government** that operates under established rules and transparent accountability. It demonstrates a commitment to precise, data-driven governance in a core administrative function, rather than an expansion of discretionary power.\n\n**National Security (Indirectly):**\nWhile not directly related to defense or intelligence, a robust and trustworthy electoral system is a pillar of domestic stability. Public confidence in election results is critical to maintaining social cohesion and preventing unrest. By rigorously auditing the ballot counting process and transparently outlining the methodology, the government indirectly contributes to **national security** by bolstering faith in democratic institutions and mitigating internal divisions that could otherwise be exploited.\n\n**Deviation/Area for Scrutiny:**\nThe documents implicitly reveal an existing national error rate (0.45% in 2019) and a tolerance for a continued, albeit low, error rate (e.g., less than 6.5 errors per 1,000 ballots nationally, or less than 1% in each state with 99% confidence). While the proposed method reduces this, a right-leaning perspective might always push for the lowest possible error rate, even zero, to maximize electoral integrity. However, the document acknowledges the practicalities and costs of achieving absolute perfection, justifying the current approach as a \"conservative\" balance between accuracy and efficiency.\n\nIn summary, the FOI documents largely depict government action that aligns with conservative principles of efficiency, fiscal prudence, safeguarding individual liberties through electoral integrity, and operating within defined roles using transparent, data-driven methods.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:14.538078", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__right_leaning__20250622T141514.json", "output_tokens": 797, "prompt_tokens": 6571, "total_tokens": 9061, "summary_length": 4421}, "short_index": {"text": "The FOI documents reveal an Australian Bureau of Statistics (ABS) methodology for auditing Senate ballots that aligns strongly with right-leaning principles, emphasizing economic efficiency and fiscal responsibility through a new assurance process that requires fewer manual checks (9,895 vs. 10,400) while simultaneously achieving higher confidence in national error rates. This optimization of resources and streamlining of operations demonstrates a clear commitment to effective taxpayer fund utilization. The core aim of a low error rate (99% confidence for less than 1% state error) directly underpins individual liberty by ensuring electoral integrity, thereby upholding the democratic process and the consent of the governed. Furthermore, the collaboration between the AEC and ABS for data-driven, transparent governance exemplifies limited government operating within defined, expert-guided roles. While acknowledging an existing low error rate and a pragmatic tolerance for a minimal level, the rigorous auditing indirectly contributes to national security by bolstering public confidence in democratic institutions, ultimately fostering social cohesion.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:18.897918", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__right_leaning__20250622T141518.json", "output_tokens": 196, "prompt_tokens": 846, "total_tokens": 1242, "summary_length": 1163}}, "government_skeptic": {"overall": {"text": "The released FOI documents, obtained only after a specific request for the *underlying methodology* beyond public outlines, shed light on the Australian Electoral Commission's (AEC) approach to \"assurance\" in Senate ballot paper audits. Far from robust oversight, the advice from the Australian Bureau of Statistics (ABS) appears to prioritize administrative convenience and cost-cutting over comprehensive scrutiny of electoral integrity.\n\nKey findings raising red flags include:\n\n*   **Reduced Scrutiny, Not Enhanced Confidence:** Despite claims of \"higher confidence in the national error rate,\" the proposed methodology actually *reduces* the total number of ballots to be assured nationally (9,895 compared to 10,400 in 2019). This reduction occurs even as the total number of Senate forms is estimated to *increase* (16.095 million vs. 15.184 million). This suggests a deliberate reduction in the proportion of ballots checked, potentially leaving more errors undetected.\n*   **Unequal Oversight and Assumed Purity:** The new model shifts away from assuring a constant number of ballots per state to a variable rate, leading to \"less ballots in the less populous states.\" While this might contribute to a \"national\" confidence figure, it means smaller jurisdictions receive significantly less individual scrutiny. This could mask localized issues or systemic problems in less visible areas. Furthermore, the methodology largely *assumes* a national error rate of 0.45% (based on 2019 data) across all states, despite acknowledging that \"the prevalence of stage 2 errors differed by state.\" This simplification could obscure actual, higher error rates in specific states.\n*   **Convenience Over Accuracy:** The document repeatedly emphasizes efficiency: \"simplifying the implementation,\" \"speed up the assurance,\" and allowing checks \"while processing is ongoing.\" This drive for speed and convenience is explicitly linked to the adoption of \"clustered sampling\" of ballots. While the report acknowledges this \"can lead to lower accuracy if errors can also be clustered together,\" it dismisses the risk by claiming \"some \u2018slack\u2019\" was already allowed. This sounds suspiciously like a trade-off where logistical ease trumps the thoroughness needed for electoral integrity.\n*   **High Tolerance for Error:** The stated confidence levels, even if achieved, permit a significant number of uncorrected errors. For example, there is \"99% confidence that nationally there are less than 6.5 errors per 1,000 ballot papers.\" While sounding small, on 16 million votes, this translates to potentially **over 104,000 undetected errors**. This indicates a high acceptable threshold for inaccuracy within the electoral system.\n*   **\"Illustrative Only\" Disclaimers:** The report undermines its own \"statistical statements\" by noting they are \"illustrative only\" and that \"Final confidence intervals will depend on the actual error rates found.\" This suggests that the \"high confidence\" they promote is based on assumptions rather than guaranteed outcomes, potentially inflating public trust in the audit process.\n*   **Minimal Stage 1 Scrutiny:** The crucial first stage of testing, ensuring the scanned image matches the physical ballot, receives even less attention: only \"1 in 10 of the ballots selected for stage 2 testing.\" This relies heavily on a 2019 finding of \"no errors,\" which is a risky assumption for future processes.\n\nIn essence, these documents reveal an electoral \"assurance\" process that appears designed to achieve a statistical comfort level with minimal effort and cost, rather than a truly exhaustive and transparent verification of every vote. The emphasis on \"efficiency\" and \"simplicity\" (for the AEC) seems to come at the expense of comprehensive scrutiny, unequal treatment of states, and a potentially high tolerance for errors, all while claiming \"high confidence\" through carefully managed statistical assumptions. This approach risks eroding public trust in the integrity of election outcomes.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:33.759903", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__government_skeptic__20250622T141533.json", "output_tokens": 812, "prompt_tokens": 6567, "total_tokens": 8711, "summary_length": 4015}, "short_index": {"text": "The released FOI documents reveal the Australian Electoral Commission's (AEC) Senate ballot audit \"assurance\" methodology, advised by the ABS, prioritizes administrative convenience and cost-cutting over genuine electoral integrity. Despite claims of \"higher confidence,\" the process inexplicably *reduces* the proportion of ballots checked nationally, shifts to unequal state scrutiny based on assumed error rates, and explicitly trades accuracy for speed through \"clustered sampling,\" even acknowledging risks. This system tolerates a high margin for error, potentially leaving over 100,000 votes undetected, while disclaimers undermine its own statistical confidence claims and crucial initial checks remain minimal. Overall, it appears designed to achieve a statistical comfort level with minimal effort rather than truly exhaustive and transparent verification, significantly risking public trust in election outcomes.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:38.624779", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__government_skeptic__20250622T141538.json", "output_tokens": 162, "prompt_tokens": 862, "total_tokens": 1543, "summary_length": 923}}, "government_apologist": {"overall": {"text": "These FOI documents clearly demonstrate the government's unwavering commitment to effective governance and the integrity of our democratic processes. They showcase how the Australian Electoral Commission (AEC) proactively sought expert statistical guidance from the Australian Bureau of Statistics (ABS) to enhance the assurance methodology for Senate ballot papers. This collaborative approach ensures that our electoral audits are grounded in robust, scientifically-backed principles.\n\nThe resulting methodology outlines a meticulous and highly efficient statistical sampling process, specifically designed to provide a high level of confidence that the national error rate in ballot processing is exceedingly low. Far from being a static process, this new approach builds on valuable lessons from the 2019 election, notably delivering higher national confidence with a reduced sample size and allowing for assurance to be undertaken concurrently with ballot processing. This represents a significant stride in operational efficiency and intelligent resource allocation, ensuring timely and accurate results for the public.\n\nUnderstanding the diverse electoral landscapes across states and territories, the ABS recommended a strategically tailored assurance rate for each region. This nuanced approach, with rates adjusted to population size, is a testament to the government's dedication to achieving uniform confidence levels and accuracy nationwide, addressing regional specificities with precision.\n\nFurthermore, the documents transparently address practical implementation challenges, such as the use of clustered sampling for logistical efficiency. This is not a compromise on integrity but a carefully balanced and expertly managed solution to ensure that the audit process is both effective and practical, without undermining statistical accuracy. The comprehensive consideration of alternative allocation models before arriving at the final recommendation further underscores the thoroughness and due diligence inherent in these processes.\n\nIn essence, these documents reveal a government dedicated to continuous improvement, leveraging inter-agency expertise, and implementing data-driven strategies to safeguard the accuracy and public trust in our elections. Every decision, from the sample rates to the implementation strategies, reflects a deep commitment to serving the public by ensuring a robust, reliable, and transparent democratic system.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:50.647205", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__government_apologist__20250622T141550.json", "output_tokens": 387, "prompt_tokens": 6571, "total_tokens": 8378, "summary_length": 2460}, "short_index": {"text": "These FOI documents unequivocally demonstrate the government's steadfast dedication to robust governance and electoral integrity, highlighting the AEC's proactive collaboration with the ABS to develop a scientifically-backed, highly efficient statistical sampling methodology for Senate ballot papers. This approach, informed by past lessons, significantly enhances confidence in an exceedingly low error rate while optimizing resource allocation through reduced sample sizes and concurrent processing. The nuanced, region-specific assurance rates and transparent management of practical challenges like clustered sampling further underscore a commitment to uniform national accuracy, continuous improvement, and the unwavering safeguarding of public trust in Australia's transparent and reliable democratic system.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:15:55.708530", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__government_apologist__20250622T141555.json", "output_tokens": 121, "prompt_tokens": 438, "total_tokens": 1291, "summary_length": 815}}, "highly_critical": {"overall": {"text": "The provided FOI documents lay bare a deeply flawed and disturbingly complacent approach to ensuring the integrity of Australian Senate elections. Far from guaranteeing accuracy, the methodology outlined by the ABS, adopted by the AEC, prioritizes administrative convenience and cost-cutting over rigorous scrutiny, effectively legitimizing a concerning level of vote miscounting.\n\n**Damning Revelations and Failures:**\n\n1.  **Explicit Acceptance of High Error Rates:** The most egregious failure is the outright admission and acceptance of significant error rates. The 2019 Senate election data, used as a baseline, already showed a national error rate of **0.45%** in Stage 2 (data extraction from scanned images). This is not \"low\" for an election; on 16 million ballots, this translates to an estimated **69,065 miscounted votes** in 2019 alone. The new methodology confidently sets an *acceptable upper limit* for errors at **0.65% nationally** (or 6.5 errors per 1,000 ballots) and a staggering **1% at the state level** (10 errors per 1,000 ballots) with 99% confidence. This means the AEC is prepared to certify results where potentially **over 100,000 votes** could be misallocated, fundamentally undermining democratic legitimacy.\n\n2.  **Sacrificing Accuracy for \"Efficiency\" and \"Speed\":** The report repeatedly justifies methodological choices by prioritizing \"speed up the assurance,\" \"simplifying the implementation,\" and allowing processing \"while ongoing.\" This explicit trade-off indicates a severe lack of commitment to absolute accuracy. The chosen clustered sampling method is even acknowledged to \"lead to lower accuracy if errors can also be clustered together,\" a known flaw accepted for logistical \"benefits.\" This is a clear case of operational convenience overriding the foundational principle of precise vote counting.\n\n3.  **Reduced Scrutiny Despite Known Issues:**\n    *   **Fewer Ballots Audited:** The proposed 2021/22 assurance will examine **fewer ballots (9,895)** than the 2019 audit (10,400), despite a larger estimated vote count. This represents a deliberate reduction in oversight.\n    *   **Dangerous Assumption for Stage 1 Testing:** The critical Stage 1 check (physical ballot matching scanned image) is drastically reduced, with only \"1 in 10 of the ballots selected for stage 2 testing\" being examined. This reduction is based on the flimsy justification of \"no errors detected\" in a small 2019 sample (1,368 ballots). To scale down vital verification on such thin evidence borders on negligence, leaving a gaping hole for undetected scanning errors or even deliberate image manipulation.\n\n4.  **Deliberate Blindness to State-Level Failures:** Despite acknowledging that \"the prevalence of stage 2 errors differed by state,\" the methodology \"assumed\" the national 0.45% error rate for each state (except ACT). This choice actively *ignores* potential higher error rates or systemic issues in individual states, effectively masking localized problems under a national average. This approach protects the \"national confidence\" statistic while potentially allowing significant, localized vote miscounts to go unchecked and unaddressed.\n\n5.  **Inflated Confidence in Flawed Metrics:** The \"high level of confidence\" touted in the executive summary refers to the confidence that the *observed* error rate will stay *below* an already unacceptably high maximum (0.65% nationally, 1% per state), not confidence in achieving near-zero errors. The use of \"round numbers\" for sampling skips, prioritizing simplicity over statistical precision, further highlights the superficiality of the \"robustness\" claims. The \"small buffer for error\" is not about striving for greater accuracy, but merely protecting the *statistical validity* of a deliberately relaxed confidence interval.\n\n6.  **\"Illustrative Only\" Disclaimers Undermine Trust:** The admission that \"These statistical statements are illustrative only. They are based on the assumption of a true error rate of 0.45%...\" reveals the precariousness of their entire confidence framework. If the foundational assumption of a low error rate is incorrect (i.e., if the true error rate is higher than 0.45%), then the entire report's \"confidence\" projections are meaningless.\n\nIn essence, these documents reveal an electoral body that, supported by its statistical advisors, has adopted a methodology designed not to eliminate errors, but to certify the results while tolerating tens of thousands of miscounted votes. This approach prioritizes operational ease and statistical appeasement over the fundamental imperative of ensuring every vote is accurately counted, casting a dark shadow over the integrity of Australia's democratic process.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:16:19.525718", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__overall__highly_critical__20250622T141619.json", "output_tokens": 1000, "prompt_tokens": 6568, "total_tokens": 10571, "summary_length": 4725}, "short_index": {"text": "The FOI documents lay bare a disturbingly complacent and fundamentally flawed approach to Australian Senate election integrity, revealing the AEC and ABS have deliberately engineered a methodology that prioritizes administrative convenience and cost-cutting over precise vote counting. This system not only explicitly accepts, but actively plans for, an \"acceptable\" error rate that could see tens of thousands, potentially over 100,000, votes miscounted, with a staggering 1% error tolerance at the state level. This deliberate sacrifice of accuracy for \"efficiency,\" compounded by reduced scrutiny, dangerous assumptions regarding Stage 1 checks, and a wilful blindness to potential state-specific failures, profoundly undermines democratic legitimacy by certifying election results riddled with significant inaccuracies, all under the guise of an \"illustrative\" and superficially robust \"confidence\" metric.", "model": "gemini-2.5-flash", "generated_at": "2025-06-22T14:16:24.459323", "source_hash": "58fd1c44f9ca1d08a21cb2e9de1f43bdd3b22fae7d96ea8916549649e3a4b207", "raw_response_path": "data/llm_responses/LEX2979__short_index__highly_critical__20250622T141624.json", "output_tokens": 162, "prompt_tokens": 1048, "total_tokens": 1782, "summary_length": 910}}}, "type_counts": {"pdf": 1, "zip": 1}, "output_html_path": "/documents/LEX2979.html"}
</script>

</body>
</html>